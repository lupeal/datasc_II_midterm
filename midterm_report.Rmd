---
title: "P8106 Midterm Project: Predicting COVID-19 Recovery Time"
author: 
  - "Guadalupe Antonio Lopez, Gustavo Garcia-Franceschini, Derek Lamb"
  -  "UNI's: GA2612, GEG2145, DRL2168"
header-includes:
    - \usepackage{setspace}\doublespacing

output: pdf_document
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
library(caret)
library(rsample)
library(corrplot)
library(gtsummary)
library(tidymodels)
library(mgcv)


knitr::opts_chunk$set(
  echo = TRUE, 
  fig.width = 6,
  out.width = "65%",
  fig.align = "center")
```

## Introduction

## EDA

```{r data import, echo=FALSE}
load("files/recovery.RData")

df_rec <- dat |> 
  select(-id)

set.seed(1)
split <- df_rec |> 
  initial_split(prop = 0.8)

df_train <- training(split)
df_test <- testing(split)
```




We also examined the pairwise correlations of the variables, and the correlations of the covariates with the recovery time. There were two clusters of strong correlation (height, weight, and BMI; hypertension and SBP), but these covariates were functionally dependent upon each other. There were no other strong correlations between variables, and no one covariate had an exceptional correlation to recovery time.

```{r corrplot, echo=FALSE}
# convert covariates to numeric
cor_rec <- df_rec |> 
  model.matrix(recovery_time ~ ., data = _) 

# put outcome back into matrix
cor_rec[,1] = df_rec$recovery_time
colnames(cor_rec)[1] <- "recovery"

# create corrplot
cor_rec |> 
  cor() |> 
  corrplot()
```
**Figure M.** Correlogram of study variables.


## Model Training
To train the models, we partitioned the data into training and testing sets, with 80% of the data (2400 subjects) being assigned to the training set, and the remaining 20% (600 subjects) being assigned to the test set.

To predict COVID-19 recovery time, we modeled the data using four approaches -- two linear and two non-linear. For the linear approaches, we selected elastic net and partial least squares regression. For the nonlinear approaches, we selected multivariate adaptive regression splines (MARS) and a general additive model (GAM).


```{r, echo = FALSE}
set.seed(1)

#matrix models
x_training <- model.matrix(recovery_time ~ ., df_train)[, -1]
y_training <- df_train$recovery_time

x_testing <- model.matrix(recovery_time ~ ., df_test)[, -1]
y_testing <- df_test$recovery_time

#10foldCV
ctrl1 <- trainControl(method = 'cv', number = 10)
```

### Elastic Net Model

```{r, echo = FALSE}
#elastic net
set.seed(1)

enet_fit <- train(recovery_time ~ .,
                  data = df_train,
                  method = 'glmnet',
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                         lambda = exp(seq(-6, 1, length = 100))),
                  trControl = ctrl1)
```



### Partial Least Squares Regression Model

```{r, echo = FALSE}
#PLS
set.seed(1)

pls_fit <- train(x_training, y_training,
                 method = 'pls',
                 tuneGrid = data.frame(ncomp = 1:15),
                 trControl = ctrl1,
                 preProcess = c('center', 'scale'))
```



### Multivariate Adaptive Regression Splines Model

```{r, echo = FALSE, message = FALSE}
#MARS
set.seed(1)

mars_fit <- train(x_training, y_training,
                  method = 'earth',
                  tuneGrid = expand.grid(degree = 1:3,
                                         nprune = 2:14),
                  trControl = ctrl1)
```



### General Additive Model

```{r, echo = FALSE, message = FALSE}
#GAM
set.seed(1)

gam_fit <- train(x_training, y_training,
                 method = 'gam',
                 trControl = ctrl1)
```








## Results 

Remember to talk about `study` as a variable.

## Conclusion

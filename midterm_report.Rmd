---
title: "P8106 Midterm Project: Predicting COVID-19 Recovery Time"
author: 
  - "Guadalupe Antonio Lopez, Gustavo Garcia-Franceschini, Derek Lamb"
  -  "UNI's: GA2612, GEG2145, DRL2168"
header-includes:
    - \usepackage{setspace}\doublespacing
    - \captionsetup[figure]{font=8}

output: pdf_document
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(rsample)
library(corrplot)
library(gtsummary)
library(mgcv)

theme_set(theme_bw() + theme(legend.position = "bottom"))

knitr::opts_chunk$set(
  echo = TRUE, 
  fig.width = 6,
  out.width = "65%",
  fig.align = "center")
```

## Introduction

This analysis combines three cohort studies regarding recovery time from COVID-19 illness. We have the individual's gender and race, along with other medical information. Among these, stand out their vaccination status and the study (A or B) they were a part of. With this information, we aim to fit a model that can both help us predict recovery time, and understand variables strongly associated with increased risk for long COVID-19 recovery times.

## Exploratory Data Analysis

To start our investigation, we conduct exploratory data analysis. To explore our data and train the models, we partitioned the data into training and testing sets, with 80% of the data (2400 subjects) being assigned to the training set, and the remaining 20% (600 subjects) being assigned to the test set. This way, the test set is not included in our EDA. The split was done with a random seed of 1.

```{r, echo = FALSE}
load("files/recovery.RData")
df_rec <- dat |> 
  select(-id)

set.seed(1)
dat_split = initial_split(data = df_rec, prop = 0.8)

df_train = training(dat_split)
df_test = testing(dat_split)
```

We have 15 variables, including our response (recovery time). We calculated summary statistics for 14 of them, grouping them by study group, since we are interested in knowing whether the two study groups are similar (**Table 1**). We noticed that they are very similar in all our proposed covariates, yet the mean recovery time for individuals in gorup B is five days more than for individuals in group A. It is also important to note that group A has almost twice as many individuals as group B.

```{r, echo = FALSE, message = FALSE}
df_train %>%
  tbl_summary(by = study,
              statistic = list(all_continuous() ~ '{mean} ({sd})',
                             all_categorical() ~ '{n} ({p}%)'),
              digits = all_continuous() ~ 3) %>%
  modify_spanning_header(c('stat_1', 'stat_2') ~ '**Study**') %>%
  modify_header(label = '**Variable**') %>%
  bold_labels() %>%
  modify_caption('Summary statistics')
```

We further investigate the relationship between study group and recovery time in **Figure 1**. We found that the COVID-19 infection recovery time is heavily right-skewed, regardless of the study group. However, Study A has a later peak, while Study B has a heavier tail, corresponding to more individuals in that study experiencing longer recovery time. This is an early indication that study group might be an important variable when predicting recovery time.

```{r density_plot_by_study, echo=FALSE, fig.cap="Recovery time density, by study group"}
df_train %>%
  ggplot() +
  geom_density(aes(x = recovery_time, col = study)) +
  theme_bw() + 
  labs(title = "The two studies have different recovery time distributions",
       x = "Recovery time (days)",
       y = "Density",
       color = "Study")
```

In **Figure 2**, we plotted our continuous variables on the x-axis, with recovery time on the y-axis. We see that bmi and height have some non-linearity, with higher bmi and lower height associated with higher recovery times, but values in the middle or opposing end not showing any particular pattern. Age, weight, SBP and LDL show some outliers in the middle of their ranges. These observations suggest we should implement models that account for non-linearity.

```{r scatterplot, echo=FALSE, fig.cap = "Continuous variables plotted against recovery time"}
x <- model.matrix(recovery_time ~ ., df_train)[, -1]
y <- df_train$recovery_time

#featurePlot(x[, c(2, 9:11, 14,15)], y, plot = 'scatter', 
#            labels = c('', 'recovery time'), type = c('p'))

selected = df_train %>%
  select(age, height, weight, bmi, SBP, LDL, recovery_time)

x <- model.matrix(recovery_time ~ ., selected)[, -1]
y <- df_train$recovery_time

featurePlot(x, y, plot = 'scatter', 
          labels = c('', 'recovery time'), type = c('p'))
```

We also examined the pairwise correlations of the variables, and the correlations of the covariates with the recovery time. There were two clusters of strong correlation (height, weight, and BMI; hypertension and SBP), but these covariates were functionally dependent upon each other. There were no other strong correlations between variables, and no one covariate had an exceptional correlation to recovery time.

```{r corrplot, echo=FALSE, fig.cap="Variable correlation plot"}
# convert covariates to numeric
cor_rec <- df_train |> 
  model.matrix(recovery_time ~ ., data = _) 

# put outcome back into matrix
cor_rec[,1] = df_train$recovery_time
colnames(cor_rec)[1] <- "recovery"

# create corrplot
cor_rec |> 
  cor() |> 
  corrplot()
```


## Model Training

To predict COVID-19 recovery time, we modeled the data using four approaches -- two linear and two non-linear. For the linear approaches, we selected elastic net and partial least squares regression. For the nonlinear approaches, we selected multivariate adaptive regression splines (MARS) and a general additive model (GAM). As specified before, we use our training set to train all models.

All models were fitted using the `train()` function in the `caret` package. Although some inputs varied by model, the common inputs were formula or model matrix and response vector, data, method, tuning parameters grid, and a 10-fold cross validation method. **Note that all models were fit using a seed of 1.**


```{r set cv splits, echo = FALSE}
set.seed(1)

#matrix models
x_training <- model.matrix(recovery_time ~ ., df_train)[, -1]
y_training <- df_train$recovery_time

x_testing <- model.matrix(recovery_time ~ ., df_test)[, -1]
y_testing <- df_test$recovery_time

#10foldCV
ctrl1 <- trainControl(method = 'cv', number = 10)
```

### Elastic Net Model

```{r enet, echo = FALSE}
#elastic net
set.seed(1)

enet_fit <- train(recovery_time ~ .,
                  data = df_train,
                  method = 'glmnet',
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                         lambda = exp(seq(-6, 1, length = 100))),
                  trControl = ctrl1)
```

To fit the elastic net model, we used the model formula with `recovery_time` as the response and all other variables in our training data set to be predictors. Given that we fit an elastic net model, the method specified was `glmnet`, with tuning parameter alpha to be sequenced between 0 and 1 (with length 21) and lambda to be exponentially sequenced between -6 and 1 (with length 100).

```{r, include = FALSE}
coef(enet_fit$finalModel, enet_fit$bestTune$lambda)
```

After fitting the elastic net model, the final model based on the optimal lambda contained 17 predictors and an intercept -- no predictors were shrunk to zero. The values for each predictor represent the estimated effect of each predictor on recovery time. Based on our output, age, height, bmi, and systolic blood pressure had positive coefficients. This suggests that an increase in a given predictor is associated with an increase in recovery time. There were also positive coefficients for categorical variables race (asian), former and current smoking status, hypertension, systolic blood pressure, severity, and study B. These positive coefficients indicate the difference in the outcome compared to their reference level. 

### Partial Least Squares (PLS) Regression Model

```{r pls, echo = FALSE}
#PLS
set.seed(1)

pls_fit <- train(x_training, y_training,
                 method = 'pls',
                 tuneGrid = data.frame(ncomp = 1:15),
                 trControl = ctrl1,
                 preProcess = c('center', 'scale'))
```

To fit the PLS model, we used the training model matrix, based on our training data, and training response vector. Given that we fit a PLS model, the method specified was `pls`, with number of components ranging between 1 and 15. This range is based on the number of variables in our training model matrix. Additionally, the predictor data was centered and scaled.


```{r, include = FALSE}
coef(pls_fit$finalModel)
```

After fitting the PLS model, the final model is based on 13 components. The positive predictor coefficients in the elastic net model were also positive in the PLS model. In this case, the positive coefficients suggest that an increase in a predictor variable (by one standard deviation) is associated with an increase in standardized recovery time by the coefficient value (with standard deviation units).


### Multivariate Adaptive Regression Splines Model

```{r mars, echo = FALSE, message = FALSE}
#MARS
set.seed(1)

mars_fit <- train(x_training, y_training,
                  method = 'earth',
                  tuneGrid = expand.grid(degree = 1:3,
                                         nprune = 2:14),
                  trControl = ctrl1)
```

To fit the MARS model, we used the training model matrix and training response vector. Given that we fit a MARS model, the method specified was `earth`, with degrees ranging between 1 and 3 and the maximum number of terms in the pruned model to range between 2 and 14.


```{r, include = FALSE}
coef(mars_fit$finalModel)
```

After fitting the MARS model, the final model is based on 12 coefficients terms including an intercept based on 9 predictors. The predictors that most inform recovery time are bmi, height, weight, vaccination status, study group B, LDL, systolic blood pressure, COVID-19 severity status, and smoking status.





### General Additive Model

```{r gam, echo = FALSE, message = FALSE}
#GAM
set.seed(1)

gam_fit <- train(x_training, y_training,
                 method = 'gam',
                 trControl = ctrl1)
```

To fit the GAM, we used the training model matrix and training response vector. Given that we fit a GAM, the method specified was `gam` and a 10-fold cross validation.

```{r, include = FALSE}
gam_fit$finalModel
```

The final GAM contains categorical predictors gender, race (all levels), current smoking status, hypertension, diabetes, vaccination status, COVID-19 severity status, study group B, and smooth terms applied to continuous variables age, systolic blood pressure, LDL, bmi, height, weight. The model has a total estimated degrees of freedom of 35.99, which suggests a relatively flexible model. 

## Results 

We then compared the four models that we fit by resampling on the training set. In the figure below, we constructed boxplots to compare the four different models by their resampled RMSE. The two linear models and GAM perform about the same, though GAM was a bit better on average. MARS noticeably outperformed the other models.

```{r resamples, echo=FALSE, fig.cap="Resampled RMSE for our four models"}
rs = resamples(list(
  ElasticNet = enet_fit,
  PLS = pls_fit,
  MARS = mars_fit,
  GAM = gam_fit
))

bwplot(rs, metric = "RMSE")
```

Once we decided on MARS as a final model, we calculated the test error using the 20% partition of the initial data set.
```{r final test error, echo=FALSE}
test_pred <- predict(mars_fit, newdata = x_testing) 
test_rmse <- sqrt(mean((test_pred - y_testing)^2))
```
The test RMSE for the MARS model is `r test_rmse |> round(digits=2)`.


## Conclusion

In this project, our goal was to use statistical learning to gain insight into the recovery process of people infected with COVID-19. We fit four models to predict COVID-19 recovery time from a set of 14 covariates, two linear and two nonlinear. Our linear models achieved similar performance in predicting recovery time, but they were outdone by the nonlinear methods, MARS in particular. This improvement in prediction is due to the greater flexibility of the nonlinear methods, but comes at a trade-off of the interpretability of such models. However, as our goal was to develop the best model for predicting COVID-19 recovery time, we are comfortable giving up some of this interpretability, and recommending the MARS model developed above for this task. Additionally, the MARS model uses study group, so we conclude that it is relevant for the model's accuracy, especially given that the two study groups looked different in our EDA.
